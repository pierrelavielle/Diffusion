{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d51ae06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Downloading torchvision-0.24.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: numpy in /home/pierre/Desktop/epita/maj/ing3/stochastique/.venv/lib/python3.12/site-packages (from torchvision) (2.3.4)\n",
      "Requirement already satisfied: torch==2.9.1 in /home/pierre/Desktop/epita/maj/ing3/stochastique/.venv/lib/python3.12/site-packages (from torchvision) (2.9.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/pierre/Desktop/epita/maj/ing3/stochastique/.venv/lib/python3.12/site-packages (from torchvision) (12.0.0)\n",
      "Requirement already satisfied: filelock in /home/pierre/Desktop/epita/maj/ing3/stochastique/.venv/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/pierre/Desktop/epita/maj/ing3/stochastique/.venv/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /home/pierre/Desktop/epita/maj/ing3/stochastique/.venv/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/pierre/Desktop/epita/maj/ing3/stochastique/.venv/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /home/pierre/Desktop/epita/maj/ing3/stochastique/.venv/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/pierre/Desktop/epita/maj/ing3/stochastique/.venv/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /home/pierre/Desktop/epita/maj/ing3/stochastique/.venv/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (2025.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/pierre/Desktop/epita/maj/ing3/stochastique/.venv/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/pierre/Desktop/epita/maj/ing3/stochastique/.venv/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/pierre/Desktop/epita/maj/ing3/stochastique/.venv/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/pierre/Desktop/epita/maj/ing3/stochastique/.venv/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/pierre/Desktop/epita/maj/ing3/stochastique/.venv/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/pierre/Desktop/epita/maj/ing3/stochastique/.venv/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/pierre/Desktop/epita/maj/ing3/stochastique/.venv/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/pierre/Desktop/epita/maj/ing3/stochastique/.venv/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/pierre/Desktop/epita/maj/ing3/stochastique/.venv/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/pierre/Desktop/epita/maj/ing3/stochastique/.venv/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /home/pierre/Desktop/epita/maj/ing3/stochastique/.venv/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /home/pierre/Desktop/epita/maj/ing3/stochastique/.venv/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/pierre/Desktop/epita/maj/ing3/stochastique/.venv/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/pierre/Desktop/epita/maj/ing3/stochastique/.venv/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/pierre/Desktop/epita/maj/ing3/stochastique/.venv/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in /home/pierre/Desktop/epita/maj/ing3/stochastique/.venv/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (3.5.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/pierre/Desktop/epita/maj/ing3/stochastique/.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch==2.9.1->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/pierre/Desktop/epita/maj/ing3/stochastique/.venv/lib/python3.12/site-packages (from jinja2->torch==2.9.1->torchvision) (3.0.3)\n",
      "Downloading torchvision-0.24.1-cp312-cp312-manylinux_2_28_x86_64.whl (8.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torchvision\n",
      "Successfully installed torchvision-0.24.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configuration\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BATCH_SIZE = 128\n",
    "LR = 1e-4\n",
    "EPOCHS = 5 # Augmenter pour de meilleurs résultats (ex: 20-50)\n",
    "TIMESTEPS = 500 # Nombre d'étapes de diffusion\n",
    "IMG_SIZE = 28\n",
    "CHANNELS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "759d2d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:01<00:00, 9.32MB/s]\n",
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 318kB/s]\n",
      "100%|██████████| 1.65M/1.65M [00:00<00:00, 2.96MB/s]\n",
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 6.72MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape du batch : torch.Size([128, 1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGcCAYAAAA2+rwbAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAHvZJREFUeJzt3HtU1HX+x/HXKHJRvIRCFnlDKFYtdbUsM8ErmruWl9VSVyEvpJbmWU2zUlETS92g1LzQZm1opV3spnkt22y3tDWtzDQvW65heCtvifL9/bGH948R1PmOEGLPxzmc8jvznvkwM/Cc78yX8TiO4wgAAEllSnoBAIBLB1EAABiiAAAwRAEAYIgCAMAQBQCAIQoAAEMUAACGKACAj3JycjR16lS99dZbJb2UYkMULmGJiYmqXbt2SS/jNyk+Pl7x8fF+zf4a99uCBQvk8Xi0e/dun84/ZMgQtWvXrljXdCmZMGGCPB6P17batWsrMTHxoi53zJgxysjI0M033+y1ffny5QoNDdWPP/54UZd/KSi1Ucj7oTjX1z//+c+SXuIlJ+8HpUyZMvruu+8KnP7TTz8pJCREHo9H9913n23fvXu33a6vvvrqOS83OzvbtiUmJio0NNTrfLm5uXrhhRfUrFkzhYWFqWLFirr22mvVt29fu79q16593vs172vBggVFdKtc/nbt2qWMjAyNHTvWtvlzn/7WLV26VC+++KKWL1+u8PBwr9M6dOig6OhopaamltDqik5ASS/gYk2cOFF16tQpsD06OroEVlM6BAUFadGiRXrwwQe9tr/22msXnJ04caK6du1a4FmYL4YNG6ZZs2bpjjvuUO/evRUQEKBt27Zp2bJlioqK0s0336y0tDQdPXrUZt59910tWrRITz75pKpVq2bbmzdv7vr63VixYoXfs/Pnz1dubm4RrubipKenq06dOmrVqlWhp1/MfVqabNu2TWXK+P88ePfu3Vq2bNk5f7ckJydr5MiRSklJUcWKFf2+npJW6qPQsWNHNW3atKSXUarcfvvthUZh4cKF6tSpU6HPHCWpUaNG2rRpk15//XV17drV1XVmZWVp9uzZGjhwoObNm+d1Wlpamu1233nnnV6n/fDDD1q0aJHuvPPOX+WltOPHj6t8+fIKDAz0+zLKlStXhCu6ODk5OcrMzNS9995b6OkXc5+6cezYMVWoUKHYLt8XQUFBFzU/fPjw857erVs33X///Vq8eLHuueeei7quklRqXz7y1fjx41WmTBmtXr3aa/ugQYMUGBiozz//3Lb961//UocOHVS5cmWVL19ecXFx+uijj7zm8narv/nmG/Xp00eVK1dWeHi4Hn30UTmOo++++0533HGHKlWqpOrVq2vGjBle8++//748Ho9efvlljR07VtWrV1eFChXUuXPnQl/SOVtubq7S0tJUv359BQcH68orr1RycrIOHTrk823Sq1cvbdq0SV9//bVt++GHH7RmzRr16tXrnHN33XWXrr32Wk2cOFFuP1x3165dchxHt956a4HTPB6PIiIiXF3ehcyePVv169dXUFCQrr76ag0dOlSHDx/2Ok98fLwaNGigjRs3qmXLlipfvry9xFLYewp79uxR586dVaFCBUVERGjEiBF677335PF49P7779v5zn5PIe+lmunTp2vevHmqW7eugoKCdOONN+rTTz/1uo7NmzcrMTFRUVFRCg4OVvXq1XXPPffowIEDft0O//jHP5Sdna22bdsWerrb+3Tx4sVq0qSJQkJCVK1aNfXp00d79+71Ok/eS4fffvutbr/9dlWsWFG9e/eWJHtpcvHixapXr55CQkJ0yy23aMuWLZKkuXPnKjo6WsHBwYqPjy/wnsmHH36oP/3pT6pZs6aCgoJUo0YNjRgxQidOnLjg2s9+TyEnJ0cpKSmKiYlRcHCwqlatqhYtWmjlypVec19//bW6d++usLAwBQcHq2nTpnrzzTcLXH5ERIRuuOEGLV269IJruZSV+igcOXJE2dnZXl/5f4AeeeQRNWrUSP3799fPP/8sSXrvvfc0f/58jRs3Tg0bNpQkrVmzRi1bttRPP/2k8ePHa8qUKTp8+LBat26tTz75pMD19uzZU7m5uZo6daqaNWumyZMnKy0tTe3atVNkZKQef/xxRUdHa+TIkVq3bl2B+ccee0zvvPOORo8erWHDhmnlypVq27btBR/cycnJGjVqlG699Valp6crKSlJmZmZSkhIUE5Ojk+3WcuWLXXNNddo4cKFtu3ll19WaGioOnXqdM65smXL6pFHHtHnn3+u119/3afrylOrVi1J//ulcvz4cVezbk2YMEFDhw7V1VdfrRkzZqhbt26aO3eu2rdvX+A2OnDggDp27KhGjRopLS3tnC+xHDt2TK1bt9aqVas0bNgwPfzww1q/fr1Gjx7t87oWLlyoadOmKTk5WZMnT9bu3bvVtWtXrzWtXLlSO3fuVFJSkp5++mndddddeumll3T77be7DrEkrV+/Xh6PR40bNy70dDf36YIFC9SjRw+VLVtWqampGjhwoF577TW1aNGiQHBPnz6thIQERUREaPr06erWrZud9uGHH+ovf/mL+vXrpwkTJmjr1q36wx/+oFmzZumpp57SkCFDNGrUKH388ccFnnHnPX4GDx6sp59+WgkJCXr66afVt29f17fNhAkTlJKSolatWmnmzJl6+OGHVbNmTX322Wd2ni+//FI333yztm7dqjFjxmjGjBmqUKGC7rzzzkJvryZNmmj9+vWu13JJcUqp5557zpFU6FdQUJDXebds2eIEBgY6AwYMcA4dOuRERkY6TZs2dXJychzHcZzc3FwnJibGSUhIcHJzc23u+PHjTp06dZx27drZtvHjxzuSnEGDBtm206dPO9dcc43j8XicqVOn2vZDhw45ISEhTr9+/Wzb2rVrHUlOZGSk89NPP9n2V155xZHkpKen27Z+/fo5tWrVsn9/+OGHjiQnMzPT6/tbvnx5odvPlrf2H3/80Rk5cqQTHR1tp914441OUlKS4ziOI8kZOnSonbZr1y5HkjNt2jTn9OnTTkxMjNOwYUO7rfJfbv61V6hQwev6+/bt60hyrrjiCqdLly7O9OnTna1bt553zdOmTXMkObt27Trv+fLs37/fCQwMdNq3b++cOXPGts+cOdOR5Pztb3+zbXFxcY4kZ86cOQUuJy4uzomLi7N/z5gxw5HkvPHGG7btxIkTTmxsrCPJWbt2rdf3nv9+y7v9qlat6hw8eNC2L1261JHkvPXWW7bt+PHjBdayaNEiR5Kzbt0625b3+L/Q7dKnTx+natWqBba7vU9PnTrlREREOA0aNHBOnDhhl/P22287kpxx48Z5ff+SnDFjxhS43ryfz/zrnjt3riPJqV69utfPxEMPPVTgeyzs9klNTXU8Ho+zZ88e25a3/vxq1arl9bPYsGFDp1OnTgUuL782bdo4119/vXPy5Enblpub6zRv3tyJiYkpcP4pU6Y4kpysrKzzXu6lrNTvKcyaNUsrV670+lq2bJnXeRo0aKCUlBRlZGQoISFB2dnZev755xUQ8L+3VDZt2qTt27erV69eOnDggO1xHDt2TG3atNG6desKvHE4YMAA+/+yZcuqadOmchxH/fv3t+1VqlTRddddp507dxZYd9++fb3ejOrevbuuuuoqvfvuu+f8XhcvXqzKlSurXbt2XntGTZo0UWhoqNauXevz7darVy/t2LFDn376qf33fC8d5f9e855ZvvHGGz5fnyQ999xzmjlzpurUqaPXX39dI0eO1O9+9zu1adOmwEsQ/lq1apVOnTqlBx54wOtNxYEDB6pSpUp65513vM4fFBSkpKSkC17u8uXLFRkZqc6dO9u24OBgDRw40Oe19ezZU1dccYX9+7bbbpMkr8dHSEiI/f/JkyeVnZ1thz/mfwbrqwMHDnhdZ2F8uU83bNig/fv3a8iQIQoODrbtnTp1UmxsbIHbVZIGDx5c6GW1adPG6+W1Zs2aSfrfa/L5fybytp/r9jl27Jiys7PVvHlzOY6jf//73+f9Ps9WpUoVffnll9q+fXuhpx88eFBr1qxRjx499PPPP3u9EpGQkKDt27cXeNzm3dal+aitUh+Fm266SW3btvX6KuwlgFGjRqlhw4b65JNPNH78eNWrV89Oy3tQ9OvXT+Hh4V5fGRkZ+uWXX3TkyBGvy6tZs6bXvytXrqzg4GCvI2Tythf2en9MTIzXvz0ej6Kjo8973Pn27dt15MgRRUREFFjn0aNHtX///nPOnq1x48aKjY3VwoULlZmZqerVq6t169Y+zfbu3VvR0dGu31soU6aMhg4dqo0bNyo7O1tLly5Vx44dtWbNGt11110+X8757NmzR5J03XXXeW0PDAxUVFSUnZ4nMjLSpzeV9+zZo7p16xY4QsfNUW5nP2byfoHkf3wcPHhQw4cP15VXXqmQkBCFh4fb0XVnPwZ95ct9dKH79Fy3qyTFxsYWuF0DAgJ0zTXXFHpdhf3sSFKNGjUK3Z7/9vnPf/6jxMREhYWFKTQ0VOHh4YqLi5Pk/vaZOHGiDh8+rGuvvVbXX3+9Ro0apc2bN9vpO3bskOM4evTRRwv8vI0fP16SCvzM5d12pflIrlJ/9JGvdu7cab/8897UypO3FzBt2jQ1atSo0Pmzj7kvW7ZsgfMUtk3y7YfSF7m5uYqIiFBmZmahp5997PSF9OrVS88884wqVqyonj17+ny4Xt4zy8TERL/fVKtatao6d+6szp07Kz4+Xh988IH27Nlj7z38WvI/8yxuvjw+evToofXr12vUqFFq1KiRQkNDlZubqw4dOvh1mGvVqlV9OgihKO7T/IKCgs75eDrX7XCh2+fMmTNq166dDh48qNGjRys2NlYVKlTQ3r17lZiY6Pr2admypb799lstXbpUK1asUEZGhp588knNmTNHAwYMsMsbOXKkEhISCr2Ms58U5N3WZz85LE1+E1HIzc1VYmKiKlWqpAceeEBTpkxR9+7d7RC8unXrSpIqVap0zqM0itrZu6yO42jHjh264YYbzjlTt25drVq1SrfeemuR/DLr1auXxo0bp3379unvf/+7q9k+ffpo8uTJSklJ8XpJxR9NmzbVBx98oH379l10FPLmt23bpqioKNt+6tQp7dq1y+/7t1atWvrqq6/kOI7Xs8AdO3Zc1HrzO3TokFavXq2UlBSNGzfOtp/r5Q1fxMbGKjMzU0eOHLFn3udyvvs0/+169h7ltm3bfpWYb9myRd98842ef/55rzeWzz5ayI2wsDAlJSUpKSlJR48eVcuWLTVhwgQNGDDAHj/lypXz+XGza9cuVatWzfUTtEtJqX/5yBd//etftX79es2bN0+TJk1S8+bNNXjwYHvdr0mTJqpbt66mT5/u9YdTeYrjT9dfeOEFOxpKkpYsWaJ9+/apY8eO55zp0aOHzpw5o0mTJhU47fTp0wWOALmQunXrKi0tTampqbrppptczeY9s9y0aVOhh+ed7YcfftBXX31VYPupU6e0evVqlSlTpkj+4LBt27YKDAzUU0895fUM/Nlnn9WRI0fOe3TV+SQkJGjv3r1e3+vJkyc1f/78i15znrxnymfvWaalpfl9mbfccoscx9HGjRt9uv5z3adNmzZVRESE5syZo19++cW2L1u2TFu3bvX7dnWjsNvHcRylp6f7dXlnH+YbGhqq6Oho+/4iIiIUHx+vuXPnat++fQXmC/u9sHHjRt1yyy1+redSUer3FJYtW+Z1vH2e5s2bKyoqSlu3btWjjz6qxMRE/fGPf5T0v0PrGjVqpCFDhuiVV15RmTJllJGRoY4dO6p+/fpKSkpSZGSk9u7dq7Vr16pSpUpF/gFYYWFhatGihZKSkpSVlaW0tDRFR0ef943LuLg4JScnKzU1VZs2bVL79u1Vrlw5bd++XYsXL1Z6erq6d+/uah0X+oOc8+ndu7cmTZqkTZs2XfC833//vW666Sa1bt1abdq0UfXq1bV//34tWrRIn3/+uR544IEi2eUODw/XQw89pJSUFHXo0EGdO3fWtm3bNHv2bN14443q06ePX5ebnJysmTNn6u6779bw4cN11VVXKTMz0950LYrXkCtVqqSWLVvqiSeeUE5OjiIjI7VixQrt2rXL78ts0aKFqlatqlWrVvn0ntG57tNy5crp8ccfV1JSkuLi4nT33XcrKytL6enpql27tkaMGOH3Gn0VGxurunXrauTIkdq7d68qVaqkV1991dXf6ORXr149xcfHq0mTJgoLC9OGDRu0ZMkSr494mTVrllq0aKHrr79eAwcOVFRUlLKysvTxxx/r+++/9/o7p/3792vz5s0aOnToRX+vJanURyH/bnZ+zz33nGrVqqV+/fqpWrVqXs+2YmJilJqaquHDh+uVV15Rjx49FB8fr48//liTJk3SzJkzdfToUVWvXl3NmjVTcnJyka977Nix2rx5s1JTU/Xzzz+rTZs2mj17tsqXL3/euTlz5qhJkyaaO3euxo4dq4CAANWuXVt9+vQp9A/DilNAQIAeeeQRn47eue6665SWlqZ3331Xs2fPVlZWloKDg9WgQQPNnz/f66itizVhwgSFh4dr5syZGjFihMLCwjRo0CBNmTLF7782Dg0N1Zo1a3T//fcrPT1doaGh6tu3r5o3b65u3bp5HZFzMRYuXKj7779fs2bNkuM4at++vZYtW6arr77ar8sLDAxU7969tXjxYk2ZMuWC5z/ffZqYmKjy5ctr6tSpGj16tCpUqKAuXbro8ccfV5UqVfxanxvlypXTW2+9pWHDhik1NVXBwcHq0qWL7rvvPvt7IzeGDRumN998UytWrNAvv/yiWrVqafLkyRo1apSdp169etqwYYNSUlK0YMECHThwQBEREWrcuHGB3z2vvfaagoKC1KNHj4v+XkuSxymqd0Hhk/fff1+tWrXS4sWLXT+rx6UnLS1NI0aM0Pfff6/IyMiSXk6hdu7cqdjYWC1btkxt2rQp6eVctho3bqz4+Hg9+eSTJb2Ui/KbeE8BKApn/7X5yZMnNXfuXMXExFyyQZCkqKgo9e/fX1OnTi3ppVy2li9fru3bt+uhhx4q6aVctFL/8hHwa+natatq1qypRo0a6ciRI3rxxRf19ddfn/MQ4UvJM888U9JLuKx16NCh0INUSiOiAPgoISFBGRkZyszM1JkzZ1SvXj299NJL6tmzZ0kvDSgyvKcAADC8pwAAMEQBAGCIAgDA+PxGc2n+1D8AgG8fzsmeAgDAEAUAgCEKAABDFAAAhigAAAxRAAAYogAAMEQBAGCIAgDAEAUAgCEKAABDFAAAhigAAAxRAAAYogAAMEQBAGCIAgDAEAUAgCEKAABDFAAAhigAAAxRAAAYogAAMEQBAGCIAgDAEAUAgCEKAABDFAAAhigAAAxRAAAYogAAMEQBAGCIAgDAEAUAgCEKAABDFAAAhigAAAxRAAAYogAAMEQBAGCIAgDAEAUAgCEKAABDFAAAhigAAAxRAAAYogAAMEQBAGCIAgDAEAUAgCEKAABDFAAAhigAAAxRAAAYogAAMEQBAGCIAgDAEAUAgCEKAABDFAAAhigAAAxRAAAYogAAMEQBAGCIAgDAEAUAgCEKAABDFAAAhigAAAxRAAAYogAAMEQBAGCIAgDAEAUAgCEKAABDFAAAhigAAAxRAACYgJJeAFCaVa5c2fVM2bJl/bquwMBA1zPjxo1zPTN48GDXM3v27HE989JLL7mekaRp06a5njlw4IBf1/VbxJ4CAMAQBQCAIQoAAEMUAACGKAAADFEAABiiAAAwRAEAYIgCAMAQBQCAIQoAAEMUAADG4ziO49MZPZ7iXgsuc9WqVfNrrnfv3q5n6tev79d1udWtWzfXM1WqVCn6hfyGNGvWzPXMhg0bimElpY8vv+7ZUwAAGKIAADBEAQBgiAIAwBAFAIAhCgAAQxQAAIYoAAAMUQAAGKIAADBEAQBgiAIAwBAFAIAJKOkFoORdeeWVrmfuvvtu1zODBw92PSNJ0dHRfs3h8hQeHl7SS7issacAADBEAQBgiAIAwBAFAIAhCgAAQxQAAIYoAAAMUQAAGKIAADBEAQBgiAIAwBAFAIDhA/GgJUuWuJ5p3rx5MaykZP3444+uZz777LNiWEnh6tSp43omJCTE9UyNGjVcz/ya/PkAx3LlyrmeycnJcT1zOWBPAQBgiAIAwBAFAIAhCgAAQxQAAIYoAAAMUQAAGKIAADBEAQBgiAIAwBAFAIAhCgAA43Ecx/HpjB5Pca8FReDll192PXPHHXe4nvHnA8b8/fC4tLQ01zNffPGF65kjR464ntm9e7frGX9FRES4ngkMDHQ9M2/ePNczCQkJrmd+TS1btnQ989FHHxXDSkqWL7/u2VMAABiiAAAwRAEAYIgCAMAQBQCAIQoAAEMUAACGKAAADFEAABiiAAAwRAEAYIgCAMAElPQCULiaNWv6NVemjPvO+/Phdhs2bHA9M2bMGNczkrR27Vq/5i43hw4dcj0zcuRI1zO33Xab65lLXWRkZEkvodRgTwEAYIgCAMAQBQCAIQoAAEMUAACGKAAADFEAABiiAAAwRAEAYIgCAMAQBQCAIQoAAEMUAADG4ziO49MZPZ7iXgvy6dixo19zb7/9tuuZ3Nxc1zPh4eGuZw4fPux65lJXtmzZX2VGkpYuXep6pn379n5d16Xs2WefdT2TnJzsesbHX42lii/fE3sKAABDFAAAhigAAAxRAAAYogAAMEQBAGCIAgDAEAUAgCEKAABDFAAAhigAAAxRAACYgJJeAAo3ePDgX+26XnjhBdczrVq1cj3z+9//3vWMJO3evdv1TP369f26Lrfq1avneqZdu3bFsJLSZ/369X7NPfjgg65nLscPtysu7CkAAAxRAAAYogAAMEQBAGCIAgDAEAUAgCEKAABDFAAAhigAAAxRAAAYogAAMEQBAGA8jo+fFOXxeIp7LcinRYsWfs2tWLHC9UxQUJBf14XL0969e13PbNmyxfVMv379XM9IUnZ2tl9z8O2DAdlTAAAYogAAMEQBAGCIAgDAEAUAgCEKAABDFAAAhigAAAxRAAAYogAAMEQBAGCIAgDA8IF4l5m4uDjXMw8++KDrmXr16rmeqVmzpusZ/L/c3FzXM8uXL3c9c++997qe8edD9PDr4wPxAACuEAUAgCEKAABDFAAAhigAAAxRAAAYogAAMEQBAGCIAgDAEAUAgCEKAABDFAAAhg/Eg19q1KjheiY6Otqv60pPT3c9U79+fb+u61LmzwcXzpgxoxhWgtKKD8QDALhCFAAAhigAAAxRAAAYogAAMEQBAGCIAgDAEAUAgCEKAABDFAAAhigAAAxRAAAYogAAMAElvQCUTv/9739dz3Tp0sWv67qUP/F06dKlrmdWr17t13XNnj3brznADfYUAACGKAAADFEAABiiAAAwRAEAYIgCAMAQBQCAIQoAAEMUAACGKAAADFEAABiiAAAwHsdxHJ/O6PEU91pQigQGBrqeOXHiRDGspOjs3LnT9UyLFi1cz2RlZbmeAYqCL7/u2VMAABiiAAAwRAEAYIgCAMAQBQCAIQoAAEMUAACGKAAADFEAABiiAAAwRAEAYIgCAMAElPQCUPIGDx7seiYtLa3oF1KEPvjgA9cz7du3dz1z+vRp1zPApYw9BQCAIQoAAEMUAACGKAAADFEAABiiAAAwRAEAYIgCAMAQBQCAIQoAAEMUAACGKAAADB+Id5lp1aqV65mePXu6ngkIcP/Qyc3NdT0jSfPmzXM9M23aNNczfLgdwJ4CACAfogAAMEQBAGCIAgDAEAUAgCEKAABDFAAAhigAAAxRAAAYogAAMEQBAGCIAgDAeBzHcXw6o8dT3GtBPtHR0X7Nvf32265nYmJiXM/4+LDx8sknn7iekaRBgwa5nvniiy/8ui7gcubLzy17CgAAQxQAAIYoAAAMUQAAGKIAADBEAQBgiAIAwBAFAIAhCgAAQxQAAIYoAAAMUQAAGKIAADB8Suqv4KqrrnI9s27dOr+uKyoqyq85t06dOuV6JiQkpBhWAsBXfEoqAMAVogAAMEQBAGCIAgDAEAUAgCEKAABDFAAAhigAAAxRAAAYogAAMEQBAGCIAgDABJT0Akqbtm3bup557LHHXM+Eh4e7nvHXkiVLXM888cQTxbASACWNPQUAgCEKAABDFAAAhigAAAxRAAAYogAAMEQBAGCIAgDAEAUAgCEKAABDFAAAhigAAIzHcRzHpzN6PMW9llJh3rx5rmf69+9fDCspOg0bNnQ988UXXxTDSgAUJ19+3bOnAAAwRAEAYIgCAMAQBQCAIQoAAEMUAACGKAAADFEAABiiAAAwRAEAYIgCAMAQBQCACSjpBZSkjh07up7585//XAwrKTpxcXGuZ7766qtiWAmA0og9BQCAIQoAAEMUAACGKAAADFEAABiiAAAwRAEAYIgCAMAQBQCAIQoAAEMUAACGKAAADFEAABiP4ziOT2f0eIp7LQCAYuTLr3v2FAAAhigAAAxRAAAYogAAMEQBAGCIAgDAEAUAgCEKAABDFAAAhigAAAxRAAAYogAAMEQBAGCIAgDAEAUAgCEKAABDFAAAhigAAAxRAAAYogAAMEQBAGCIAgDAEAUAgCEKAABDFAAAJsDXMzqOU5zrAABcAthTAAAYogAAMEQBAGCIAgDAEAUAgCEKAABDFAAAhigAAAxRAACY/wPeMq6Ea705QAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda t: (t * 2) - 1)\n",
    "])\n",
    "\n",
    "dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "\n",
    "image, _ = next(iter(dataloader))\n",
    "print(f\"Shape du batch : {image.shape}\")\n",
    "plt.imshow(image[0, 0].cpu(), cmap='gray')\n",
    "plt.title(\"Exemple MNIST original (Normalisé)\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb379d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffusionUtils:\n",
    "    def __init__(self, timesteps=TIMESTEPS, start=0.0001, end=0.02, device=DEVICE):\n",
    "        self.timesteps = timesteps\n",
    "        self.device = device\n",
    "        \n",
    "        self.betas = torch.linspace(start, end, timesteps).to(device)\n",
    "        self.alphas = 1. - self.betas\n",
    "        self.alphas_cumprod = torch.cumprod(self.alphas, axis=0)\n",
    "        \n",
    "    def forward_noise(self, x_0, t):\n",
    "        \"\"\"\n",
    "        Ajoute du bruit à l'image x_0 à l'instant t.\n",
    "        Retourne : l'image bruitée (x_t) et le bruit ajouté (noise)\n",
    "        \"\"\"\n",
    "        sqrt_alphas_cumprod = torch.sqrt(self.alphas_cumprod[t])[:, None, None, None]\n",
    "        sqrt_one_minus_alphas_cumprod = torch.sqrt(1. - self.alphas_cumprod[t])[:, None, None, None]\n",
    "        \n",
    "        noise = torch.randn_like(x_0)\n",
    "        return sqrt_alphas_cumprod * x_0 + sqrt_one_minus_alphas_cumprod * noise, noise\n",
    "\n",
    "    def sample_timesteps(self, n):\n",
    "        \"\"\"Retourne des indices de temps aléatoires pour le training\"\"\"\n",
    "        return torch.randint(0, self.timesteps, (n,), device=self.device)\n",
    "\n",
    "diff_utils = DiffusionUtils()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce8eae67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle U-Net chargé.\n"
     ]
    }
   ],
   "source": [
    "class TimeEmbedding(nn.Module):\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.n_embd = n_embd\n",
    "        self.lin1 = nn.Linear(self.n_embd // 4, self.n_embd)\n",
    "        self.lin2 = nn.Linear(self.n_embd, self.n_embd)\n",
    "\n",
    "    def forward(self, t):\n",
    "        # Encodage sinusoïdal simple (positional encoding)\n",
    "        half_dim = self.n_embd // 8\n",
    "        emb = torch.log(torch.tensor(10000.0)) / (half_dim - 1)\n",
    "        emb = torch.exp(torch.arange(half_dim, device=t.device) * -emb)\n",
    "        emb = t[:, None] * emb[None, :]\n",
    "        emb = torch.cat((emb.sin(), emb.cos()), dim=1)\n",
    "        return self.lin2(F.silu(self.lin1(emb)))\n",
    "\n",
    "class SimpleUNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Time embedding\n",
    "        time_dim = 32\n",
    "        self.time_mlp = TimeEmbedding(time_dim)\n",
    "\n",
    "        # Encoder (Down)\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1) # 28x28\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, stride=2, padding=1) # 14x14\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, stride=2, padding=1) # 7x7\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bot1 = nn.Conv2d(128, 256, 3, padding=1)\n",
    "        self.bot2 = nn.Conv2d(256, 128, 3, padding=1)\n",
    "\n",
    "        # Decoder (Up)\n",
    "        self.up1 = nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1) # 14x14\n",
    "        self.up2 = nn.ConvTranspose2d(64, 32, 4, stride=2, padding=1) # 28x28\n",
    "        self.out = nn.Conv2d(32, 1, 3, padding=1)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        # Gestion du temps\n",
    "        t_emb = self.time_mlp(t)\n",
    "        # Projection du temps pour qu'il matche les dimensions des channels (broadcasting)\n",
    "        t_emb_1 = t_emb[:, :, None, None] \n",
    "        \n",
    "        # --- Encoder ---\n",
    "        x1 = F.relu(self.conv1(x))\n",
    "        x2 = F.relu(self.conv2(x1))\n",
    "        x3 = F.relu(self.conv3(x2))\n",
    "\n",
    "        # --- Bottleneck ---\n",
    "        x_bot = F.relu(self.bot1(x3))\n",
    "        x_bot = F.relu(self.bot2(x_bot))\n",
    "        \n",
    "        # --- Decoder (avec Skip Connections simplifiées par addition ici) ---\n",
    "        # Note: Pour un vrai U-Net rigoureux on concatène, ici on additionne pour simplifier le code\n",
    "        x_up1 = F.relu(self.up1(x_bot + x3)) \n",
    "        x_up2 = F.relu(self.up2(x_up1 + x2))\n",
    "        \n",
    "        return self.out(x_up2 + x1)\n",
    "\n",
    "model = SimpleUNet().to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "criterion = nn.MSELoss()\n",
    "print(\"Modèle U-Net chargé.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54286680",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "    for batch in pbar:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        images, _ = batch\n",
    "        images = images.to(DEVICE)\n",
    "        \n",
    "        # 1. Échantillonner t\n",
    "        t = diff_utils.sample_timesteps(images.shape[0]).float() # float pour l'embedding\n",
    "        \n",
    "        # 2. Créer l'image bruitée (x_t) et garder le bruit cible (noise)\n",
    "        x_t, noise = diff_utils.forward_noise(images, t.long())\n",
    "        \n",
    "        # 3. Prédiction du bruit\n",
    "        noise_pred = model(x_t, t)\n",
    "        \n",
    "        # 4. Calcul de la perte (MSE entre le vrai bruit et le bruit prédit)\n",
    "        loss = criterion(noise_pred, noise)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        pbar.set_postfix(MSE=loss.item())\n",
    "        losses.append(loss.item())\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.title(\"Courbe de Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6cfa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def sample_images(model, diff_utils, n_samples=8):\n",
    "    model.eval()\n",
    "    \n",
    "    # On commence avec du bruit pur (Gaussian noise)\n",
    "    x = torch.randn((n_samples, 1, IMG_SIZE, IMG_SIZE)).to(DEVICE)\n",
    "    \n",
    "    # Boucle inversée : de T-1 jusqu'à 0\n",
    "    for i in tqdm(reversed(range(1, TIMESTEPS)), desc=\"Sampling\", total=TIMESTEPS-1):\n",
    "        t = (torch.ones(n_samples) * i).long().to(DEVICE)\n",
    "        \n",
    "        # Le modèle prédit le bruit à retirer\n",
    "        predicted_noise = model(x, t.float()) # t float pour l'embedding\n",
    "        \n",
    "        # Formule de sampling (simplifiée DDPM)\n",
    "        alpha = diff_utils.alphas[t][:, None, None, None]\n",
    "        alpha_hat = diff_utils.alphas_cumprod[t][:, None, None, None]\n",
    "        beta = diff_utils.betas[t][:, None, None, None]\n",
    "        \n",
    "        if i > 1:\n",
    "            noise = torch.randn_like(x)\n",
    "        else:\n",
    "            noise = torch.zeros_like(x)\n",
    "            \n",
    "        # On retire une partie du bruit\n",
    "        x = (1 / torch.sqrt(alpha)) * (x - ((1 - alpha) / (torch.sqrt(1 - alpha_hat))) * predicted_noise) + torch.sqrt(beta) * noise\n",
    "        \n",
    "    model.train()\n",
    "    \n",
    "    # On remet les pixels entre 0 et 1 pour l'affichage\n",
    "    x = (x.clamp(-1, 1) + 1) / 2\n",
    "    return x\n",
    "\n",
    "# Génération\n",
    "generated_images = sample_images(model, diff_utils)\n",
    "\n",
    "# Affichage\n",
    "fig, axes = plt.subplots(1, 8, figsize=(15, 2))\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.imshow(generated_images[i][0].cpu(), cmap='gray')\n",
    "    ax.axis('off')\n",
    "plt.suptitle(\"Chiffres générés par Diffusion\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
